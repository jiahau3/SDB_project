# Preprocessing

## Data pipeline for preprocessing Sentinel 2 data

The notebook [03](https://dagshub.com/Omdena/Glintsolar/src/master/preprocessing/notebooks/03_aws_cog_exploration.ipynb), [04](https://dagshub.com/Omdena/Glintsolar/src/master/preprocessing/notebooks/04_data_set_preparation.ipynb), and [this](https://dagshub.com/Omdena/Glintsolar/src/master/preprocessing/notebooks/Load_clip_images.ipynb) show the preprocessing steps for generating training data for modeling. S2 data is retreived through [STAC API](https://pystac-client.readthedocs.io/en/latest/usage.html). Taking the advantage of [stackstac](https://stackstac.readthedocs.io/en/latest/), it turns STAC items into DataArray, a data sctructure generated by [xarray library](https://docs.xarray.dev/en/stable/). It is processed through clipping, mosaicing before storing whole raster data into memory. The output is a rater data with resampled depth information added at the last entities of channels.

## Following is the attempt for using Data Cube. Corresponding notebook is 02_open_data_cube..

## Hosting Your Own Data Cube

### Warning

__First of all: Windows Users beware if you want to use Earth Engine in the background -> this won't work for you if you don't custom-build GDAL!__
__If you still want to do this on Windows use the Subsystem for Linux__

### Database

If you want to run your own data cube use the following docker command:

```bash
docker run -d --name datacube-postgis -v <the-directory-you-want-to-mount>:/var/lib/postgresql -p 5432:5432 -e POSTGRES_PASSWORD=datacube postgis/postgis:13-3.1
```

After that connect to the container and start psql

```bash
docker exec -ti datacube-postgis psql -U postgres
```

Now you can create the datacube database and close the session of the container.

```sql
CREATE DATABASE datacube;
```

Finally initialize the datacube schema using the CLI you installed when getting the `datacube` python packages. If you followed all the instructions in this
Readme you can use the config provided in the repository, otherwise you would need to adapt it for your environment.

```bash
datacube --config .\preprocessing\config\datacube.conf -v system init
```

### Google Earth Engine Indexing

For real time indexing using Google Earth Engine please follow the instructions [here](https://github.com/ceos-seo/odc-gee).

### Conclusion and Alternatives

Be aware that setting up your own data cube might be a very daunting task. Also the realtime indexing with Google Earth engine doesn't work very well. The
most stable thing you could do is to index datasets yourself, ingest certain parts and work from there. Personally speaking I think we would have better
chances using the [AWS Landsat-2 Cloud Optimizes geoTIFFs](https://registry.opendata.aws/sentinel-2-l2a-cogs/) and querying it over their STAC endpoint
using [intak](https://intake-stac.readthedocs.io/en/latest/).
